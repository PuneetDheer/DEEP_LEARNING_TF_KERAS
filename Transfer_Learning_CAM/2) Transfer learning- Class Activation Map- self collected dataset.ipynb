{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, signal\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential,load_model, model_from_yaml\n",
    "from tensorflow.keras.layers import Dense,Flatten,GlobalAveragePooling2D\n",
    "from tensorflow.keras import models,Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR='C:\\g_images\\downloads\\originals'\n",
    "CLASSES = ['cats','dogs','panda','bikes','horse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[] #list\n",
    "training_label=[]\n",
    "training_data_raw=[] #list\n",
    "\n",
    "img_resize = 224\n",
    "\n",
    "def self_generated_train_data():\n",
    "    for c in CLASSES:\n",
    "        path = os.path.join(DATA_DIR,c)\n",
    "        class_no = CLASSES.index(c)\n",
    "        for img in os.listdir(path):\n",
    "            #print(os.path.join(path,img))\n",
    "            img_array_bgr = cv2.imread(os.path.join(path,img))\n",
    "            rgb_img = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2RGB)\n",
    "            rgb_image_resized = cv2.resize(rgb_img,(img_resize,img_resize)) #cv2.resize() follows (width,height) unlike as expected (height, width)\n",
    "            training_data.append(rgb_image_resized) #append array to a list\n",
    "            training_label.append(class_no)\n",
    "            training_data_raw.append(rgb_img) \n",
    "                        \n",
    "        print(\"Class %d loaded: %s \"%(class_no,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_generated_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the resized data to prevent from re-loading\n",
    "\n",
    "pickle_out=open(\"training_data_224px_VGG16.pickle\",'wb')\n",
    "pickle.dump(training_data,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out=open(\"training_label_224px_VGG16.pickle\",'wb')\n",
    "pickle.dump(training_label,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out=open(\"training_data_224px_VGG16_raw.pickle\",'wb')\n",
    "pickle.dump(training_data_raw,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load the resized data\n",
    "pickle_in = open(\"training_data_224px_VGG16.pickle\",'rb')\n",
    "training_data = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"training_label_224px_VGG16.pickle\",'rb')\n",
    "training_label = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"training_data_224px_VGG16_raw.pickle\",'rb')\n",
    "training_data_raw = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into an array for model input\n",
    "training_data = np.array(training_data)\n",
    "training_label = np.array(training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2750, 224, 224, 3)\n",
      "Training label shape: (2750,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\",training_data.shape)\n",
    "print(\"Training label shape:\",training_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2192821e0b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: {0: 550, 1: 550, 2: 550, 3: 550, 4: 550}\n"
     ]
    }
   ],
   "source": [
    "Class_label_counters = {label:list(training_label).count(label) for label in list(training_label)}\n",
    "print('Class counts:',Class_label_counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of classes: 5\n"
     ]
    }
   ],
   "source": [
    "total_classes = len(np.unique(training_label))\n",
    "print('Total Number of classes:',total_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_categorical = to_categorical(training_label,total_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data \n",
    "training_data = training_data.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the dataset\n",
    "x_shuffle,y_shuffle = shuffle(training_data,y_categorical,random_state=15)\n",
    "x_shuffle_raw,_ = shuffle(training_data_raw,y_categorical,random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data split\n",
    "X, X_test, Y, Y_test = train_test_split(x_shuffle,y_shuffle,test_size = 0.10,random_state=16)\n",
    "_, X_test_raw, _, _ = train_test_split(x_shuffle_raw,y_shuffle,test_size = 0.10,random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and valid data split\n",
    "X_train,X_valid,Y_train,Y_valid = train_test_split(X,Y,test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape after split: (275, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data shape after split:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape after split: (1980, 224, 224, 3)\n",
      "Validation data shape after split: (495, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape after split:\",X_train.shape)\n",
    "print(\"Validation data shape after split:\",X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label shape after split: (1980, 5)\n",
      "Validation label shape after split: (495, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training label shape after split:\",Y_train.shape)\n",
    "print(\"Validation label shape after split:\",Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pretrained Model VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0909 00:15:08.384948 13456 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelVGG = VGG16(weights ='imagenet',include_top = True)\n",
    "modelVGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_VGG = Model(inputs = modelVGG.input,outputs = modelVGG.layers[-6].output)\n",
    "CNN_VGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new model\n",
    "gap_NN = Sequential()\n",
    "gap_NN.add(GlobalAveragePooling2D())\n",
    "gap_NN.add(Dense(5,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 14,717,253\n",
      "Trainable params: 14,717,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# this way only save the weights not the architecture, we have to recreate the same architecture to load the saved weights\n",
    "full_model = Model(inputs = CNN_VGG.input, \n",
    "                   outputs = gap_NN(CNN_VGG.output))\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or in another way, it will save weights and architecture\n",
    "\n",
    "# last_conv_layer = modelVGG.get_layer('block5_conv3').output # modelVGG.layers[-6].output\n",
    "# gap_layer = GlobalAveragePooling2D()(last_conv_layer)\n",
    "# classification_layer = Dense(5,activation = 'softmax')(gap_layer)\n",
    "\n",
    "# full_model = Model(inputs = modelVGG.input, \n",
    "#                    outputs = classification_layer)\n",
    "\n",
    "# full_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x0000021903A9A978> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021903A9A5F8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021939211CF8> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000021903AFF9E8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021903EB82B0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021903ED94E0> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000021903EE60F0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021904ACDF60> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021904AE9BE0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021904B03278> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000021904B357B8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021906EB38D0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021906EDB8D0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021906F02588> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000021907D340F0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021907D6CB70> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021907D985C0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000021907DB20F0> False\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021911167400> True\n"
     ]
    }
   ],
   "source": [
    "for layer in full_model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                       min_delta=0.001,\n",
    "                                       patience=10,\n",
    "                                       verbose=1, \n",
    "                                       mode='min',\n",
    "                                       restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('VGG16_CAM_mc.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_LR_OnPlateau = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                        factor=0.1,\n",
    "                                        patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1980 samples, validate on 495 samples\n",
      "Epoch 1/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 1.3592 - acc: 0.5282\n",
      "Epoch 00001: val_acc improved from -inf to 0.73939, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 137s 69ms/sample - loss: 1.3582 - acc: 0.5298 - val_loss: 1.1305 - val_acc: 0.7394\n",
      "Epoch 2/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.9850 - acc: 0.8137\n",
      "Epoch 00002: val_acc improved from 0.73939 to 0.83636, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 124s 63ms/sample - loss: 0.9840 - acc: 0.8131 - val_loss: 0.8910 - val_acc: 0.8364\n",
      "Epoch 3/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.8032 - acc: 0.8478\n",
      "Epoch 00003: val_acc improved from 0.83636 to 0.86667, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.8031 - acc: 0.8485 - val_loss: 0.7525 - val_acc: 0.8667\n",
      "Epoch 4/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.8555\n",
      "Epoch 00004: val_acc improved from 0.86667 to 0.88687, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.6922 - acc: 0.8566 - val_loss: 0.6601 - val_acc: 0.8869\n",
      "Epoch 5/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.6146 - acc: 0.8743\n",
      "Epoch 00005: val_acc did not improve from 0.88687\n",
      "1980/1980 [==============================] - 96s 49ms/sample - loss: 0.6132 - acc: 0.8753 - val_loss: 0.5958 - val_acc: 0.8747\n",
      "Epoch 6/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.5572 - acc: 0.8748\n",
      "Epoch 00006: val_acc did not improve from 0.88687\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.5551 - acc: 0.8758 - val_loss: 0.5492 - val_acc: 0.8828\n",
      "Epoch 7/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.5126 - acc: 0.8870\n",
      "Epoch 00007: val_acc improved from 0.88687 to 0.89091, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.5112 - acc: 0.8874 - val_loss: 0.5050 - val_acc: 0.8909\n",
      "Epoch 8/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.4738 - acc: 0.8947\n",
      "Epoch 00008: val_acc improved from 0.89091 to 0.89697, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.4730 - acc: 0.8949 - val_loss: 0.4711 - val_acc: 0.8970\n",
      "Epoch 9/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.4440 - acc: 0.9018\n",
      "Epoch 00009: val_acc improved from 0.89697 to 0.91313, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 99s 50ms/sample - loss: 0.4441 - acc: 0.9020 - val_loss: 0.4419 - val_acc: 0.9131\n",
      "Epoch 10/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.4189 - acc: 0.9008\n",
      "Epoch 00010: val_acc did not improve from 0.91313\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.4191 - acc: 0.9015 - val_loss: 0.4216 - val_acc: 0.9051\n",
      "Epoch 11/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.3961 - acc: 0.9059\n",
      "Epoch 00011: val_acc did not improve from 0.91313\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.3958 - acc: 0.9056 - val_loss: 0.3988 - val_acc: 0.9091\n",
      "Epoch 12/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.3762 - acc: 0.9130\n",
      "Epoch 00012: val_acc improved from 0.91313 to 0.91515, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.3761 - acc: 0.9121 - val_loss: 0.3835 - val_acc: 0.9152\n",
      "Epoch 13/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.9135\n",
      "Epoch 00013: val_acc did not improve from 0.91515\n",
      "1980/1980 [==============================] - 101s 51ms/sample - loss: 0.3588 - acc: 0.9136 - val_loss: 0.3743 - val_acc: 0.9030\n",
      "Epoch 14/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.3451 - acc: 0.9181\n",
      "Epoch 00014: val_acc improved from 0.91515 to 0.91717, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 157s 79ms/sample - loss: 0.3445 - acc: 0.9182 - val_loss: 0.3585 - val_acc: 0.9172\n",
      "Epoch 15/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.3289 - acc: 0.9232\n",
      "Epoch 00015: val_acc did not improve from 0.91717\n",
      "1980/1980 [==============================] - 109s 55ms/sample - loss: 0.3302 - acc: 0.9217 - val_loss: 0.3476 - val_acc: 0.9111\n",
      "Epoch 16/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.3191 - acc: 0.9262\n",
      "Epoch 00016: val_acc improved from 0.91717 to 0.92929, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.3179 - acc: 0.9268 - val_loss: 0.3301 - val_acc: 0.9293\n",
      "Epoch 17/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.3060 - acc: 0.9262\n",
      "Epoch 00017: val_acc improved from 0.92929 to 0.93131, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.3062 - acc: 0.9263 - val_loss: 0.3234 - val_acc: 0.9313\n",
      "Epoch 18/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2975 - acc: 0.9308\n",
      "Epoch 00018: val_acc did not improve from 0.93131\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.2974 - acc: 0.9303 - val_loss: 0.3124 - val_acc: 0.9313\n",
      "Epoch 19/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.9282\n",
      "Epoch 00019: val_acc did not improve from 0.93131\n",
      "1980/1980 [==============================] - 96s 49ms/sample - loss: 0.2881 - acc: 0.9288 - val_loss: 0.3046 - val_acc: 0.9293\n",
      "Epoch 20/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2789 - acc: 0.9328\n",
      "Epoch 00020: val_acc improved from 0.93131 to 0.93535, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.2790 - acc: 0.9328 - val_loss: 0.2966 - val_acc: 0.9354\n",
      "Epoch 21/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2687 - acc: 0.9344\n",
      "Epoch 00021: val_acc improved from 0.93535 to 0.93737, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.2703 - acc: 0.9333 - val_loss: 0.2889 - val_acc: 0.9374\n",
      "Epoch 22/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2631 - acc: 0.9349\n",
      "Epoch 00022: val_acc did not improve from 0.93737\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.2633 - acc: 0.9343 - val_loss: 0.2847 - val_acc: 0.9354\n",
      "Epoch 23/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2539 - acc: 0.9384\n",
      "Epoch 00023: val_acc did not improve from 0.93737\n",
      "1980/1980 [==============================] - 98s 49ms/sample - loss: 0.2556 - acc: 0.9369 - val_loss: 0.2784 - val_acc: 0.9354\n",
      "Epoch 24/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2496 - acc: 0.9399\n",
      "Epoch 00024: val_acc did not improve from 0.93737\n",
      "1980/1980 [==============================] - 97s 49ms/sample - loss: 0.2484 - acc: 0.9404 - val_loss: 0.2721 - val_acc: 0.9333\n",
      "Epoch 25/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2420 - acc: 0.9425\n",
      "Epoch 00025: val_acc did not improve from 0.93737\n",
      "1980/1980 [==============================] - 115s 58ms/sample - loss: 0.2421 - acc: 0.9424 - val_loss: 0.2684 - val_acc: 0.9374\n",
      "Epoch 26/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2369 - acc: 0.9435\n",
      "Epoch 00026: val_acc did not improve from 0.93737\n",
      "1980/1980 [==============================] - 114s 57ms/sample - loss: 0.2361 - acc: 0.9439 - val_loss: 0.2628 - val_acc: 0.9354\n",
      "Epoch 27/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2313 - acc: 0.9440\n",
      "Epoch 00027: val_acc did not improve from 0.93737\n",
      "1980/1980 [==============================] - 104s 53ms/sample - loss: 0.2312 - acc: 0.9439 - val_loss: 0.2587 - val_acc: 0.9374\n",
      "Epoch 28/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2248 - acc: 0.9461\n",
      "Epoch 00028: val_acc did not improve from 0.93737\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.2256 - acc: 0.9455 - val_loss: 0.2544 - val_acc: 0.9354\n",
      "Epoch 29/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2204 - acc: 0.9450\n",
      "Epoch 00029: val_acc did not improve from 0.93737\n",
      "1980/1980 [==============================] - 104s 53ms/sample - loss: 0.2203 - acc: 0.9455 - val_loss: 0.2513 - val_acc: 0.9333\n",
      "Epoch 30/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2159 - acc: 0.9496\n",
      "Epoch 00030: val_acc improved from 0.93737 to 0.94141, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.2154 - acc: 0.9500 - val_loss: 0.2484 - val_acc: 0.9414\n",
      "Epoch 31/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9476\n",
      "Epoch 00031: val_acc did not improve from 0.94141\n",
      "1980/1980 [==============================] - 104s 52ms/sample - loss: 0.2119 - acc: 0.9475 - val_loss: 0.2434 - val_acc: 0.9333\n",
      "Epoch 32/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2088 - acc: 0.9501\n",
      "Epoch 00032: val_acc did not improve from 0.94141\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.2085 - acc: 0.9505 - val_loss: 0.2408 - val_acc: 0.9414\n",
      "Epoch 33/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9486\n",
      "Epoch 00033: val_acc did not improve from 0.94141\n",
      "1980/1980 [==============================] - 104s 53ms/sample - loss: 0.2026 - acc: 0.9485 - val_loss: 0.2352 - val_acc: 0.9414\n",
      "Epoch 34/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1989 - acc: 0.9506\n",
      "Epoch 00034: val_acc did not improve from 0.94141\n",
      "1980/1980 [==============================] - 104s 53ms/sample - loss: 0.1994 - acc: 0.9505 - val_loss: 0.2341 - val_acc: 0.9374\n",
      "Epoch 35/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1950 - acc: 0.9496\n",
      "Epoch 00035: val_acc did not improve from 0.94141\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.1950 - acc: 0.9495 - val_loss: 0.2295 - val_acc: 0.9394\n",
      "Epoch 36/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1911 - acc: 0.9537\n",
      "Epoch 00036: val_acc did not improve from 0.94141\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.1925 - acc: 0.9530 - val_loss: 0.2284 - val_acc: 0.9394\n",
      "Epoch 37/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9522\n",
      "Epoch 00037: val_acc did not improve from 0.94141\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.1876 - acc: 0.9525 - val_loss: 0.2253 - val_acc: 0.9354\n",
      "Epoch 38/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1849 - acc: 0.9562\n",
      "Epoch 00038: val_acc improved from 0.94141 to 0.94343, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.1851 - acc: 0.9566 - val_loss: 0.2285 - val_acc: 0.9434\n",
      "Epoch 39/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1774 - acc: 0.9547\n",
      "Epoch 00039: val_acc improved from 0.94343 to 0.94545, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 104s 53ms/sample - loss: 0.1805 - acc: 0.9520 - val_loss: 0.2214 - val_acc: 0.9455\n",
      "Epoch 40/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1802 - acc: 0.9547\n",
      "Epoch 00040: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.1790 - acc: 0.9551 - val_loss: 0.2184 - val_acc: 0.9414\n",
      "Epoch 41/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9542\n",
      "Epoch 00041: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.1749 - acc: 0.9540 - val_loss: 0.2227 - val_acc: 0.9354\n",
      "Epoch 42/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9567\n",
      "Epoch 00042: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 104s 53ms/sample - loss: 0.1732 - acc: 0.9566 - val_loss: 0.2136 - val_acc: 0.9455\n",
      "Epoch 43/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1693 - acc: 0.9573\n",
      "Epoch 00043: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.1698 - acc: 0.9571 - val_loss: 0.2119 - val_acc: 0.9414\n",
      "Epoch 44/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9583\n",
      "Epoch 00044: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.1671 - acc: 0.9586 - val_loss: 0.2101 - val_acc: 0.9434\n",
      "Epoch 45/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1648 - acc: 0.9573\n",
      "Epoch 00045: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 104s 53ms/sample - loss: 0.1650 - acc: 0.9576 - val_loss: 0.2078 - val_acc: 0.9414\n",
      "Epoch 46/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9593\n",
      "Epoch 00046: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.1620 - acc: 0.9591 - val_loss: 0.2052 - val_acc: 0.9434\n",
      "Epoch 47/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9598\n",
      "Epoch 00047: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.1596 - acc: 0.9601 - val_loss: 0.2034 - val_acc: 0.9434\n",
      "Epoch 48/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9613\n",
      "Epoch 00048: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 105s 53ms/sample - loss: 0.1570 - acc: 0.9616 - val_loss: 0.2034 - val_acc: 0.9414\n",
      "Epoch 49/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9598\n",
      "Epoch 00049: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 104s 52ms/sample - loss: 0.1552 - acc: 0.9601 - val_loss: 0.2015 - val_acc: 0.9455\n",
      "Epoch 50/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9618\n",
      "Epoch 00050: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 103s 52ms/sample - loss: 0.1529 - acc: 0.9621 - val_loss: 0.2013 - val_acc: 0.9455\n",
      "Epoch 51/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9603\n",
      "Epoch 00051: val_acc did not improve from 0.94545\n",
      "1980/1980 [==============================] - 104s 53ms/sample - loss: 0.1500 - acc: 0.9601 - val_loss: 0.2065 - val_acc: 0.9414\n",
      "Epoch 52/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9618\n",
      "Epoch 00052: val_acc improved from 0.94545 to 0.94747, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 104s 52ms/sample - loss: 0.1489 - acc: 0.9616 - val_loss: 0.1964 - val_acc: 0.9475\n",
      "Epoch 53/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9623\n",
      "Epoch 00053: val_acc did not improve from 0.94747\n",
      "1980/1980 [==============================] - 104s 52ms/sample - loss: 0.1467 - acc: 0.9626 - val_loss: 0.1997 - val_acc: 0.9455\n",
      "Epoch 54/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9649\n",
      "Epoch 00054: val_acc improved from 0.94747 to 0.95354, saving model to VGG16_CAM_mc.h5\n",
      "1980/1980 [==============================] - 103s 52ms/sample - loss: 0.1448 - acc: 0.9646 - val_loss: 0.1932 - val_acc: 0.9535\n",
      "Epoch 55/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9659\n",
      "Epoch 00055: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 103s 52ms/sample - loss: 0.1428 - acc: 0.9657 - val_loss: 0.1945 - val_acc: 0.9434\n",
      "Epoch 56/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9644\n",
      "Epoch 00056: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 103s 52ms/sample - loss: 0.1410 - acc: 0.9646 - val_loss: 0.1903 - val_acc: 0.9495\n",
      "Epoch 57/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9659\n",
      "Epoch 00057: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 103s 52ms/sample - loss: 0.1383 - acc: 0.9657 - val_loss: 0.1905 - val_acc: 0.9515\n",
      "Epoch 58/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9654\n",
      "Epoch 00058: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 103s 52ms/sample - loss: 0.1373 - acc: 0.9652 - val_loss: 0.1884 - val_acc: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9674\n",
      "Epoch 00059: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 103s 52ms/sample - loss: 0.1357 - acc: 0.9672 - val_loss: 0.1886 - val_acc: 0.9475\n",
      "Epoch 60/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9628\n",
      "Epoch 00060: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 103s 52ms/sample - loss: 0.1340 - acc: 0.9626 - val_loss: 0.1859 - val_acc: 0.9495\n",
      "Epoch 61/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9674\n",
      "Epoch 00061: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 104s 53ms/sample - loss: 0.1329 - acc: 0.9677 - val_loss: 0.1857 - val_acc: 0.9495\n",
      "Epoch 62/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9659\n",
      "Epoch 00062: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 112s 56ms/sample - loss: 0.1307 - acc: 0.9662 - val_loss: 0.1870 - val_acc: 0.9455\n",
      "Epoch 63/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9669\n",
      "Epoch 00063: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 122s 62ms/sample - loss: 0.1280 - acc: 0.9672 - val_loss: 0.1867 - val_acc: 0.9495\n",
      "Epoch 64/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9684\n",
      "Epoch 00064: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 122s 62ms/sample - loss: 0.1275 - acc: 0.9687 - val_loss: 0.1820 - val_acc: 0.9495\n",
      "Epoch 65/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9715\n",
      "Epoch 00065: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 122s 62ms/sample - loss: 0.1258 - acc: 0.9712 - val_loss: 0.1834 - val_acc: 0.9495\n",
      "Epoch 66/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9695\n",
      "Epoch 00066: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 122s 62ms/sample - loss: 0.1246 - acc: 0.9692 - val_loss: 0.1801 - val_acc: 0.9475\n",
      "Epoch 67/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9695\n",
      "Epoch 00067: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 122s 61ms/sample - loss: 0.1229 - acc: 0.9697 - val_loss: 0.1792 - val_acc: 0.9515\n",
      "Epoch 68/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9695\n",
      "Epoch 00068: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 122s 61ms/sample - loss: 0.1218 - acc: 0.9697 - val_loss: 0.1829 - val_acc: 0.9515\n",
      "Epoch 69/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9690\n",
      "Epoch 00069: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 122s 61ms/sample - loss: 0.1194 - acc: 0.9692 - val_loss: 0.1791 - val_acc: 0.9475\n",
      "Epoch 70/70\n",
      "1965/1980 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9715\n",
      "Epoch 00070: val_acc did not improve from 0.95354\n",
      "1980/1980 [==============================] - 122s 62ms/sample - loss: 0.1188 - acc: 0.9717 - val_loss: 0.1768 - val_acc: 0.9475\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "history = full_model.fit(X_train, Y_train, \n",
    "                    epochs=70, \n",
    "                    batch_size=15,\n",
    "                    validation_data = (X_valid,Y_valid),\n",
    "                    callbacks=[early_stopping,model_checkpoint,reduce_LR_OnPlateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.save('camTL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_model.load_weights('camTL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 60s 217ms/sample - loss: 0.1583 - acc: 0.9491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1582523331380874, 0.9490909]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.evaluate(X_test,Y_test,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_weights = full_model.layers[-1].get_weights()[0] #last layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Weight:  (512, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Weight: ',classifier_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new model that will return two output\n",
    "cam_model2 = Model(inputs=full_model.input,\n",
    "                  outputs=(full_model.layers[-2].output, full_model.layers[-1].output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Activation_maps, Predict_prob = cam_model2.predict(X_test,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((275, 14, 14, 512), (275, 5))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Activation_maps.shape, Predict_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_plot(datasetSize = X_test,dataset_2 = X_test_raw, plotting = True):\n",
    "\n",
    "    num_images = 10\n",
    "\n",
    "    random_test_image_ind = np.random.randint(datasetSize.shape[0], size=num_images)\n",
    "    \n",
    "    if plotting:\n",
    "            plt.figure(figsize=(20, 6))\n",
    "\n",
    "    for i,image_index in enumerate(random_test_image_ind):\n",
    "\n",
    "        Activation_map_for_one_img = Activation_maps[image_index, :, :, :]\n",
    "\n",
    "        pred_id = np.argmax(Predict_prob[image_index])\n",
    "\n",
    "        predicted_class_weights = classifier_weights[:,pred_id]\n",
    "\n",
    "        cam = np.zeros(dtype = np.float32, shape = Activation_map_for_one_img.shape[0:2])\n",
    "\n",
    "        for j, w in enumerate(predicted_class_weights):\n",
    "\n",
    "            cam += np.dot(w, Activation_map_for_one_img[:, :, j])\n",
    "\n",
    "        cam/=np.max(cam)\n",
    "\n",
    "        cam = cv2.resize(cam, (X_test_raw[image_index].shape[1], X_test_raw[image_index].shape[0]))\n",
    "\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
    "\n",
    "        heatmap = np.maximum(heatmap,0)\n",
    "        heatmap[np.where(cam<0.2)]=0\n",
    "\n",
    "        superimposed_img = heatmap*0.5 + (X_test_raw[image_index])\n",
    "\n",
    "        if plotting:\n",
    "            \n",
    "            ax = plt.subplot(2, num_images/2, i+1)\n",
    "            plt.imshow(np.uint8(superimposed_img))\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "        fn = 'image_'+str(image_index)+'.jpg'\n",
    "        cv2.imwrite(fn, (superimposed_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 377.281729221344 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(100):\n",
    "    cam_plot(dataset_2=X_test_raw,plotting=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if functional module is followed by sequential module \n",
    "# then trying to save the model only allow to store the weights not the architecture.\n",
    "\n",
    "# better to write the code in funtional followed by functional"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
